{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trabalho de An√°lise de Sentimentos   </h2>\n",
    "<br>\n",
    "<b>Equipe: Igor, Jane, Jerusa e Leila   <br>\n",
    "  O artigo completo sobre Repeated k-Fold Cross-Validation pode ser encontrado neste site \n",
    "<a href='https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/'> neste dataset </a><br>\n",
    "    \n",
    "\n",
    "<h5>Vers√£o 12/09/2020 - Criada a fun√ß√£o Trata_Emojis() que traduz o sentimento da imagem.<br>\n",
    "    Vers√£o 27/08/2020 - Corrigido arquivos com neutras e sem neutras.<br>\n",
    "    Vers√£o 10/08/2020 - Organizado em fun√ß√µes e com o repeat k-fold. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informando o n√∫mero desejado de repeti√ß√µes para K-fold\n",
    "nrMaxTestes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "import regex\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.svm          import LinearSVC\n",
    "from sklearn.cluster      import KMeans\n",
    "from sklearn.multiclass   import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets        import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import LinearSVC\n",
    "from matplotlib              import pyplot\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn import utils\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "def Carrega_Arquivo(plota_grafico):\n",
    "    #arquivo_f = 'Suicidas_NaoSuicidas_Testar-20200521.csv'\n",
    "    arquivo_f = 'Suicidas_NaoSuicidas_Testar-20200718.csv'\n",
    "    cabecalho_f = ['Polaridade', 'Frase']\n",
    "    with open(arquivo_f, 'rb') as f:\n",
    "        result_f = chardet.detect(f.read()) \n",
    "    data = pd.read_csv(arquivo_f, encoding=result_f['encoding'], sep=';', header=None, names=cabecalho_f)\n",
    "    \n",
    "    # Excluindo os registros com frase nulas\n",
    "    data = data[pd.notnull(data['Frase'])]\n",
    "\n",
    "    # criou a coluna Polaridade_id no dataframe df, que cont√©m o nome polaridade representado por n√∫mero\n",
    "    data['Polaridade_id'] = data['Polaridade'].factorize()[0]\n",
    "\n",
    "    if plota_grafico == 'SIM':\n",
    "        data['Polaridade'].value_counts().plot(kind='pie');\n",
    "        plt.title('ESSA √â A DISTRIBUI√á√ÉO DOS DADOS DE ENTRADA')\n",
    "        plt.savefig(\"distribuicao_dados.png\")\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_Parametros():\n",
    "    efile = open(\"parametros.txt\", \"r\")\n",
    "    parametros = []\n",
    "    for nr, linha in enumerate(efile):\n",
    "        conteudo = linha.split(\";\") \n",
    "        parametros.append(conteudo) \n",
    "    efile.close()\n",
    "    return(parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Limpa_emojis(linha):\n",
    "    \n",
    "    data = regex.findall(r'\\X', linha)\n",
    "    for word in data:        \n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            # Remove emoji do texto\n",
    "            \n",
    "        \n",
    "    return (linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Of course, (too many) emoji [a lot] characters      feliz  like  , #@^!*&#@^#   helps   people read  achando engra√ßado demais aa achando engra√ßado demais aaa achando engra√ßado demais a #douchebag\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# https://emojipedia.org/people/\n",
    "# https://www.emoticonsignificado.com.br/lista-emojis-pessoas-whatsapp\n",
    "def Trata_Emojis(linha):\n",
    "    # Dicion√°rio de emojis e emo√ß√µes\n",
    "    emojis_lista = [('üòä', ' feliz '), \n",
    "                    ('ü§£', ' super feliz '), \n",
    "                    ('üòÇ', ' achando engra√ßado demais ')\n",
    "                    ('üò¢', ' triste ')\n",
    "                    ('üò≠', ' muito triste ')\n",
    "                    ('üò°', ' furioso ')\n",
    "                    ('üò±', ' assustado ')\n",
    "                    ('üò©', ' chateado ')\n",
    "                    ('üò∞', ' ansioso ')\n",
    "                    ('ü§©', ' encantado')]\n",
    "    emojis_dict = dict(emojis_lista)\n",
    "    \n",
    "    # quebra a linha em caracteres \n",
    "    linha_quebrada = regex.findall(r'\\X', linha)\n",
    "     \n",
    "    for char in linha_quebrada:\n",
    "        if char in emoji.UNICODE_EMOJI:\n",
    "            char_demojize = emoji.demojize(char)\n",
    "            y = emoji.emojize(char_demojize)\n",
    "            emoji_sentimento =  emojis_dict.get(y, ' ')\n",
    "            linha = linha.replace(char, emoji_sentimento)  \n",
    "         \n",
    "    return(linha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_Stopwords():\n",
    "    stopwords_nltk = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    f = open('stop_palavras.txt', 'r', encoding = 'utf-8')\n",
    "    tudo =  f.read()\n",
    "    palavras =  set(tudo.split())\n",
    "    nltk_mais_palavras = stopwords_nltk.union(palavras)\n",
    "    return(nltk_mais_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Limpa_Texto(instancia):\n",
    "    instancia = instancia.lower()  \n",
    "    acentos = str.maketrans(\"√°√©√≠√≥√∫√¢√™√¥√£√µ\", \"aeiouaeoao\") \n",
    "    instancia = instancia.translate(acentos)\n",
    "    \n",
    "    instancia = Trata_Emojis(instancia)\n",
    "    instancia = re.sub(r'\\|\\|\\|', r'', instancia) \n",
    "    instancia = re.sub(r'http\\S+', r'', instancia)\n",
    "    instancia = instancia.replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','')    \n",
    "    instancia = instancia.replace('[','').replace(']','').replace('@','').replace('(','').replace('/','')   \n",
    "    instancia = instancia.replace('#','').replace('RT @','').replace('rt cvvoficial','')\n",
    "    instancia = instancia.replace('!','').replace('?','')\n",
    "   \n",
    "    stopwords = Carrega_Stopwords()\n",
    "    palavras = []\n",
    "    for i in instancia.split():\n",
    "        if not i.isnumeric(): \n",
    "            if not i in stopwords:\n",
    "                palavras.append(i)\n",
    "        \n",
    "               \n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aplica_Stemizacao(instancia):\n",
    "    palavras = [stemmer.stem(i)  for i in instancia.split()]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    \n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transforma_Doc2vec(t_frases, t_polaridades):\n",
    "    \n",
    "    df_teste = pd.DataFrame({'Frase': t_frases, 'Polaridade_id':t_polaridades})\n",
    "    df_teste['tokenized'] = df_teste.apply(lambda row: nltk.word_tokenize(row['Frase']), axis=1)\n",
    "\n",
    "    train_tagged = df_teste.apply(\n",
    "            lambda r: TaggedDocument(r.tokenized, tags=[r.Polaridade_id]), axis=1)\n",
    "    \n",
    "    model_dmm = Doc2Vec(dm=1, vector_size=300, window=3, min_count=2, workers=cores)\n",
    "    model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "        model_dmm.alpha -= 0.002\n",
    "        model_dmm.min_alpha = model_dmm.alpha\n",
    "\n",
    "    y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "\n",
    "    # adapta as features a uma escala de [0 at√© 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X_train = scaler.fit_transform(list(X_train))\n",
    "\n",
    "    return(scaled_X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_features_labels(tipo_NLP, q_frases, q_polaridades ):\n",
    "    \n",
    "    rotulos = q_polaridades\n",
    "      \n",
    "    if tipo_NLP == 'CountVectorizer':\n",
    "        v = CountVectorizer()\n",
    "        vetores = v.fit_transform(q_frases) \n",
    "        \n",
    "    if tipo_NLP == 'TF_IDF':\n",
    "        tfidf = TfidfVectorizer(use_idf=True, max_features=300, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "        vetores = tfidf.fit_transform(q_frases) \n",
    "        \n",
    "    if tipo_NLP == 'DOC2VEC':\n",
    "        vetores, rotulos  = Transforma_Doc2vec(q_frases, q_polaridades)\n",
    "    \n",
    " \n",
    "    return(vetores, rotulos)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcula_Acuracia_Modelos(features, labels, MaxTeste, tipo_NLP, resultados, com_stemizacao, com_neutras):\n",
    "    \n",
    "    \n",
    "    models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        LinearSVC(),\n",
    "        #OneVsRestClassifier(LinearSVC(), n_jobs=1),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(random_state=0) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    print('Tipo Conversao NLP=> %s - stemizacao= %s e neutras=%s' %  (tipo_NLP, com_stemizacao, com_neutras))\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "         \n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        \n",
    "        results = []\n",
    "        numero = 0 \n",
    "        for repeats in range(1,MaxTeste):\n",
    "            CV = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "            # n_jobs = -1 significa usar todos os processadores\n",
    "            scores = cross_val_score(model, features, labels, scoring='accuracy', cv=CV, n_jobs=-1)\n",
    "            print('Modelo %s > Repeti√ß√µes=%d m√©dia=%.4f desvio padr√£o=%.3f' % (model_name, repeats, mean(scores), sem(scores)))\n",
    "           \n",
    "            # guarda o resultado\n",
    "            results.append(scores)\n",
    "            numero = repeats * 10 \n",
    "            #numero = int((numero + 1) * 10 )\n",
    "            resultados.append((tipo_NLP, com_stemizacao, testa_com_Neutra, numero, model_name, mean(scores)))\n",
    "            \n",
    "        # cria gr√°fico dos resultados\n",
    "        #pyplot.boxplot(results, labels=[str(r) for r in range(1,MaxTeste)], showmeans=True)\n",
    "        #pyplot.title(model_name)\n",
    "        #pyplot.show()\n",
    "        \n",
    "    return()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostrar_max_por_modelo(modelo, data_teste):\n",
    " \n",
    "    eh_modelo =  data_teste['tipo_NLP']==modelo\n",
    "    data_filtrada = data_teste[eh_modelo]\n",
    "    \n",
    "    max_value = data_filtrada['media_acuracia'].max()\n",
    "    eh_maior  = data_filtrada['media_acuracia']==max_value\n",
    "    data_filtrada = data_filtrada[eh_maior]\n",
    "    return(data_filtrada) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Resultados(Nome_Arquivo):\n",
    "\n",
    "    data_mostra = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "\n",
    "    # mostra execu√ß√£o que apresentou a maior acur√°cia\n",
    "    maximo = data_mostra['media_acuracia'].idxmax()\n",
    "    rowData = data_mostra.loc[maximo , : ]\n",
    "    linha_com_maximo = rowData.values.tolist()\n",
    "    df_teste = pd.DataFrame([linha_com_maximo])\n",
    "    df_teste.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "   \n",
    "    # mostra M√°xima Acur√°cia por Modelo = \n",
    "    teste1 = Mostrar_max_por_modelo('CountVectorizer', data_mostra)\n",
    "    teste2 = Mostrar_max_por_modelo('TF_IDF', data_mostra)\n",
    "    teste3 = Mostrar_max_por_modelo('DOC2VEC', data_mostra)\n",
    "    teste_r = pd.concat([teste1, teste2, teste3])\n",
    "    teste_r.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    # mostra Valor Medio de Acuracia nas Itera√ß√µes\n",
    "    Valor_Medio_Acuracia = data_mostra.groupby(['tipo_NLP', 'model_name']).agg({'media_acuracia': ['mean']})\n",
    "    Valor_Medio_Acuracia.columns = [ 'Acur√°cia M√©dia']\n",
    "     \n",
    "    return(df_teste, teste_r, Valor_Medio_Acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Grafico(Nome_Arquivo):\n",
    "    # li dados\n",
    "    data_grafico = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "    data_grafico.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    # cria um DataFrame Pandas com resultado do filtro\n",
    "    result = data_grafico.groupby(['tipo_NLP','model_name'])[['media_acuracia']].mean()\n",
    "\n",
    "    # gera uma lista com os valores de acur√°cia \n",
    "    valores = list(result.media_acuracia) \n",
    "\n",
    "    labels = list(np.unique(data_grafico.model_name))\n",
    "\n",
    "    # os 4 primeiros na lista de valores s√£o do countvectorizer\n",
    "    medias_countvectorizer = valores[0:4]\n",
    "    medias_tfidf = valores[4:8]\n",
    "    medias_doc2vec = valores[8:12]\n",
    "\n",
    "    # Definindo a largura das barras\n",
    "    barWidth = 0.25\n",
    "\n",
    "    # Aumentando o gr√°fico\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Definindo a posi√ß√£o das barras\n",
    "    r1 = np.arange(len(medias_countvectorizer))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    # Criando as barras\n",
    "    plt.bar(r1, medias_countvectorizer, color='#6A5ACD', width=barWidth, label='CountVectorizer')\n",
    "    plt.bar(r2, medias_tfidf, color='#00BFFF', width=barWidth, label='TF-IDF')\n",
    "    plt.bar(r3, medias_doc2vec, color='#48F317', width=barWidth, label='DOC2VEC')\n",
    "\n",
    "    # Adiciando legendas as barras\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.xticks([r + barWidth for r in range(len(medias_countvectorizer))], labels)\n",
    "    plt.ylabel('Acur√°cia M√©dia')\n",
    "    plt.title('Representa√ß√£o Acur√°cia M√©dia por Modelo')\n",
    "        \n",
    "\n",
    "    # Criando a legenda e exibindo o gr√°fico\n",
    "    plt.legend()\n",
    "    plt.savefig(\"acuracia_por_modelo.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Grafico_por_Opcao(Nome_Arquivo, opcao):\n",
    "    \n",
    "    arquivo_res = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "    arquivo_res.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    if opcao == 'SEM_NEUTRAS':\n",
    "        data_grafico = arquivo_res[arquivo_res['testa_com_Neutra'] == 'NAO']\n",
    "        titulo = 'Sem Incluir Frases Neutras'\n",
    "        nome_grafico = 'sem_neutras.png'\n",
    "    elif opcao == \"COM_STEMMIZACAO\":\n",
    "        data_grafico = arquivo_res[arquivo_res['com_stemizacao'] == 'SIM']\n",
    "        titulo = 'Utilizando a Stemmiza√ß√£o'\n",
    "        nome_grafico = 'com_stemizacao.png'\n",
    "        \n",
    "    # cria um DataFrame Pandas com resultado do filtro\n",
    "    result = data_grafico.groupby(['tipo_NLP','model_name'])[['media_acuracia']].mean()\n",
    "\n",
    "    # gera uma lista com os valores de acur√°cia \n",
    "    valores = list(result.media_acuracia) \n",
    "\n",
    "    labels = list(np.unique(data_grafico.model_name))\n",
    "   \n",
    "    # os 4 primeiros na lista de valores s√£o do countvectorizer\n",
    "    medias_countvectorizer = valores[0:4]\n",
    "    medias_tfidf = valores[4:8]\n",
    "    medias_doc2vec = valores[8:12]\n",
    "\n",
    "    # Definindo a largura das barras\n",
    "    barWidth = 0.25\n",
    "\n",
    "    # Aumentando o gr√°fico\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Definindo a posi√ß√£o das barras\n",
    "    r1 = np.arange(len(medias_countvectorizer))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    # Criando as barras\n",
    "    plt.bar(r1, medias_countvectorizer, color='#6A5ACD', width=barWidth, label='CountVectorizer')\n",
    "    plt.bar(r2, medias_tfidf, color='#00BFFF', width=barWidth, label='TF-IDF')\n",
    "    plt.bar(r3, medias_doc2vec, color='#48F317', width=barWidth, label='DOC2VEC')\n",
    "\n",
    "    # Adiciando legendas as barras\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.xticks([r + barWidth for r in range(len(medias_countvectorizer))], labels)\n",
    "    plt.ylabel('Acur√°cia M√©dia')\n",
    "    plt.title(titulo)\n",
    "\n",
    "    # Criando a legenda e exibindo o gr√°fico\n",
    "    plt.legend()\n",
    "    plt.savefig(nome_grafico)\n",
    "    plt.show()\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grava_Resultados(resultados):\n",
    "    NomArq = 'resultados_'  + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.csv'\n",
    "    resultados_df = pd.DataFrame(resultados, columns=['tipo_NLP', 'com_stemizacao', 'testa_com_Neutra','repeticoes', 'model_name', 'media_acuracia'])\n",
    "    resultados_df.to_csv(NomArq)\n",
    "    return(NomArq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INICIO DO PROCESSAMENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = Carrega_Arquivo('SIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplica a fun√ß√£o de limpeza de caracteres em todos os dados:\n",
    "data.Frase = [Limpa_Texto(i) for i in data.Frase]\n",
    "\n",
    "# cria coluna com frases stemizadas \n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "data['Frase_Stemm'] = [Aplica_Stemizacao(j) for j in data.Frase]\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro  = data['Polaridade'] != 'Neutra'\n",
    "data_sem_neutras = data[filtro]\n",
    "#data_sem_neutras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frases limpas s√£o salvas para uso em outros programas.\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "# Salvando dataframe para usar em Pipe_Doc2Vec\n",
    "pickle.dump(data, open(\"dados_treino.pickle\", 'wb'))\n",
    "\n",
    "# Salvando frases para usar no K-Means\n",
    "frases_file = 'Frases_Limpas.pickle'\n",
    "pickle.dump(data.Frase, open(frases_file, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explica√ß√£o sobre K-repeated e K-fold est√° na √∫ltima c√©lula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca defini√ß√µes para par√¢metros\n",
    "parametros = Carrega_Parametros()\n",
    "\n",
    "# inicializa lista de resultados\n",
    "resultados = []\n",
    "\n",
    "for lin in range(1,len(parametros)):\n",
    "\n",
    "    tipo_NLP         = parametros[lin][0]\n",
    "    com_stemizacao   = parametros[lin][1]\n",
    "    testa_com_Neutra = parametros[lin][2]\n",
    "    com_stemizacao   = com_stemizacao.strip()\n",
    "    testa_com_Neutra = testa_com_Neutra.strip()\n",
    "\n",
    "    x_frases = []\n",
    "    if testa_com_Neutra == 'SIM':\n",
    "        x_polaridades = data.Polaridade_id \n",
    "        \n",
    "        if com_stemizacao == 'SIM':\n",
    "            x_frases = data.Frase_Stemm\n",
    "            \n",
    "        if com_stemizacao == 'NAO':\n",
    "            x_frases = data.Frase\n",
    "            \n",
    "\n",
    "    if testa_com_Neutra == 'NAO':\n",
    "        x_polaridades = data_sem_neutras.Polaridade_id \n",
    "        \n",
    "        if com_stemizacao == 'SIM':\n",
    "            x_frases = data_sem_neutras.Frase_Stemm\n",
    "           \n",
    "        if com_stemizacao == 'NAO':\n",
    "            x_frases = data_sem_neutras.Frase \n",
    "    \n",
    "\n",
    "    \n",
    "    features, labels = Carrega_features_labels(tipo_NLP, x_frases, x_polaridades)\n",
    "      \n",
    "    Calcula_Acuracia_Modelos(features, labels, nrMaxTestes, tipo_NLP, resultados, com_stemizacao, testa_com_Neutra)\n",
    "\n",
    "# salva os resultados\n",
    "print('*** Salvando Resultados ***')\n",
    "Nome_Arquivo = Grava_Resultados(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra os resultados\n",
    "df1, df2, df3 = Mostra_Resultados(Nome_Arquivo)\n",
    "printmd('**Maior Acur√°cia nos Testes**')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**M√°xima Acur√°cia por Modelo**')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Valor Medio de Acuracia nas Itera√ß√µes**')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta gr√°fico contendo as m√©dias de acur√°cia encontradas\n",
    "Mostra_Grafico(Nome_Arquivo)\n",
    "Mostra_Grafico_por_Opcao(Nome_Arquivo, \"SEM_NEUTRAS\")\n",
    "Mostra_Grafico_por_Opcao(Nome_Arquivo, \"COM_STEMMIZACAO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ==> Escolhemos manualmente o modelo que apresentou melhor performance <br>\n",
    "    <br>\n",
    "\n",
    " \n",
    " ## Observando resultados acima vimos que:\n",
    " <h3><i> Os resultados mostram que o LinearSVC apresentou melhor performance,tanto com TF-IDF quanto DOC2VEC:<br>\n",
    "    -     LinearSVC                     0.780115  (TFIDF)<br>   \n",
    "    -     LinearSVC                     0.769629 (DOC2VEC) <br>\n",
    " o Multinomial foi o melhor para CountVectorizer. <br>\n",
    " Al√©m disso, observamos que a melhor acur√°cia aconteceu quando  NAO usamos Neutras e NAO usamos stemiza√ß√£o.\n",
    " \n",
    "\n",
    "- A maior acur√°cia foi igual a 0.8498508098891732, utilizando o modelo Multinomial, usando 'CountVectorizer'.<br>\n",
    "\n",
    "- Embora o CountVectorizer tenha apresentado melhor acur√°cia, o m√©todo √© considerado menos <br>\n",
    "  eficiente que o TF-IDF, por essa raz√£o estamos elegendo o que apresentou melhor desempenho no TF-IDF.\n",
    "  \n",
    "- A seguir treinaremos o LinearSVC, com TF-IDF, sem stemiza√ß√£o e sem frases Neutras. </i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><i><b>Valida√ß√£o cruzada do k-Fold</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando o arquivo sem usar frases neutras e a coluna 'Frase'  que n√£o tem stemmiza√ß√£o\n",
    "# n√£o incluir neutras => usar  data_sem_neutras\n",
    "# incluir stemmiza√ß√£o => usar data.Frase_Stemm\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a linearSVC model using k-fold cross-validation\n",
    "# https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets        import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import LinearSVC\n",
    "from matplotlib              import pyplot\n",
    "\n",
    "#tfidf = TfidfVectorizer(use_idf=True, max_features=300, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "tfidf = TfidfVectorizer(use_idf=True, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "\n",
    "# prepara labels e features\n",
    "#features = tfidf.fit_transform(data_sem_neutras.Frase)\n",
    "#features = tfidf.fit_transform(data_sem_neutras.Frase_Stemm)\n",
    "#labels = data_sem_neutras.Polaridade_id\n",
    "features = tfidf.fit_transform(data.Frase)\n",
    "#features = tfidf.fit_transform(data.Frase_Stemm)\n",
    "labels = data.Polaridade_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria matriz para mostrar palavras utilizadas \n",
    "matriz_tfidf = pd.DataFrame(features.toarray(), columns=tfidf.get_feature_names())\n",
    "matriz_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avalia o modelo com um dado nr de repeti√ß√µes\n",
    "def evaluate_model(X, y, repeats):\n",
    "    # prepara a cross-validation  \n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # cria o modelo\n",
    "    model = LinearSVC()\n",
    "    # avalia o modelo\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return(scores)  \n",
    "\n",
    "# configura√ß√µes de teste\n",
    "results = list()\n",
    "\n",
    "for r in range(1,16):\n",
    "    scores = evaluate_model(features, labels, r)\n",
    "    print('LinearSVC > Repeti√ß√µes=%d m√©dia=%.4f desvio padr√£o=%.3f ' % (r, mean(scores), sem(scores)))\n",
    "    \n",
    "    # guarda o resultado\n",
    "    results.append(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria gr√°fico dos resultados\n",
    "pyplot.boxplot(results, labels=[str(r) for r in range(1,16)], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " ## Analisando resultados:\n",
    "<i>\n",
    "- A linha laranja indica a mediana da distribui√ß√£o e o tri√¢ngulo verde representa a m√©dia aritm√©tica. Na sexta repeti√ß√£o vemos que  os valores coincidem, e isso sugere uma distribui√ß√£o sim√©trica bem razo√°vel, e que a m√©dia conseguiu capturar bem a tend√™ncia central. Isso nos ajuda a escolher o n√∫mero apropriado de repeti√ß√µes para o processo de teste. <br>\n",
    "Usaremos 6 repeti√ß√µes.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o LinearSVC utilizando TF-IDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm             import LinearSVC \n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "# Separando dados de treino e teste \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.10, random_state=0)\n",
    "\n",
    "\n",
    "# Treina o modelo\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "\n",
    "Score = model.score(X_test,y_test) \n",
    "print('Score=', Score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Modelo Vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# O Modelo √© salvo para classificar twitters no programa Analise_Twitters_CVV.ipynb.\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "#os.chdir('C:\\\\Users\\\\particular\\\\SERIQUE_TCC\\\\FINAL DA POS\\\\')\n",
    "\n",
    "# Salvando modelo\n",
    "model_file = 'model_LinearSVC.pickle'\n",
    "pickle.dump(model, open(model_file, 'wb'))\n",
    "\n",
    "# Salvando tfidf\n",
    "tfidf_file = 'tfidf_file.pickle'\n",
    "pickle.dump(tfidf, open(tfidf_file, 'wb'))\n",
    "\n",
    "print(\"Dados salvos!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio para polaridade  \n",
    "id_to_Polaridade = {0: 'Negativa', 1: 'Positiva', 2: 'Neutra'}\n",
    "\n",
    "texts = [\"Estou em beco sem saida, o unico jeito √© tomar todos comprimidos e dormir para sempre.\",\n",
    "         \"Estranho que n√£o sinto for√ßas para levantar da cama. Preciso de ajuda.\",\n",
    "         \"Adoro viver, cantar e sorrir todo dia.\", \n",
    "          \"Minha vida √© um pesadelo imenso, estou muito triste.\", \n",
    "          \"O jogo foi adiado para amanh√£.\"]\n",
    "corretas = [1, 1, 0, 1, 2]\n",
    "\n",
    "text_features = tfidf.transform(texts)\n",
    "\n",
    "nr = 0 \n",
    "acertou = 0 \n",
    "predictions = model.predict(text_features)\n",
    "for text, predicted in zip(texts, predictions):\n",
    "    print('\"{}\"'.format(text))\n",
    "    print(\"  - Classificada como: '{}'\".format(id_to_Polaridade[predicted]))\n",
    "    print(\"  - O correto √©      : '{}'\".format(id_to_Polaridade[corretas[nr]]))\n",
    "    print(\"\")\n",
    "    if predicted == corretas[nr]:\n",
    "        acertou += 1\n",
    "    nr += 1\n",
    "print('-' * 50)\n",
    "print('acertou = ', acertou,  '/', len(texts)) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUS√ÉO: A assertividade em frases que n√£o estavam no modelo foi p√©ssima, apesar do modelo ter sido considerado o melhor nos testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('*** A C A B E I ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b> Descobrindo o melhor k-fold.</b>\n",
    "O procedimento de valida√ß√£o cruzada com dobra k divide um conjunto de dados limitado em k dobras sem sobreposi√ß√£o. Cada uma das k dobras tem a oportunidade de ser usada como um conjunto de testes retidos, enquanto todas as outras dobras coletivamente s√£o usadas como um conjunto de dados de treinamento. Um total de k modelos s√£o ajustados e avaliados nos conjuntos de testes de espera k e o desempenho m√©dio √© relatado.\n",
    "   \n",
    "¬® A valida√ß√£o cruzada repetida em dobra k replica o procedimento [‚Ä¶] v√°rias vezes. Por exemplo, se a valida√ß√£o cruzada 10 vezes foi repetida cinco vezes, 50 conjuntos diferentes retidos seriam usados para estimar a efic√°cia do modelo.¬®\n",
    "\n",
    "- P√°gina 70, Modelagem Preditiva Aplicada , 2013.\n",
    "Applied Predictive Modeling 1st ed. 2013, Corr. 2nd printing 2018 Edition\n",
    "by Max Kuhn  (Author), Kjell Johnson  (Author)\n",
    "    \n",
    "  \n",
    "O desempenho m√©dio relatado de uma √∫nica execu√ß√£o de valida√ß√£o cruzada k-fold pode ser barulhento.\n",
    "A valida√ß√£o cruzada repetida de dobras k fornece uma maneira de reduzir o erro na estimativa do desempenho m√©dio do modelo.\n",
    "Como avaliar modelos de aprendizado de m√°quina usando a valida√ß√£o cruzada k-fold repetida no Python.\n",
    "\n",
    "Nesse caso, podemos ver que o padr√£o de uma repeti√ß√£o parece otimista em compara√ß√£o com os outros resultados, com uma precis√£o de cerca de 86,80 por cento em compara√ß√£o com 86,73 por cento e menor com n√∫meros diferentes de repeti√ß√µes.\n",
    "\n",
    "Podemos ver que a m√©dia parece coalescer em torno de um valor de cerca de 86,5%. Podemos considerar isso como uma estimativa est√°vel do desempenho do modelo e, por sua vez, escolher 5 ou 6 repeti√ß√µes que parecem aproximar esse valor primeiro.\n",
    "\n",
    "Observando o erro padr√£o, podemos ver que ele diminui com um aumento no n√∫mero de repeti√ß√µes e se estabiliza com um valor em torno de 0,003, em torno de 9 ou 10 repeti√ß√µes, embora 5 repeti√ß√µes atinjam um erro padr√£o de 0,005, metade da alcan√ßada com um repeti√ß√£o √∫nica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos variar os seguintes par√¢metros:<br>\n",
    "Se dm = 0, √© usado opacote distribu√≠do de palavras (PV-DBOW) ; <br>\n",
    "se dm = 1, 'mem√≥ria distribu√≠da' (PV-DM) √© usada. <br>\n",
    "Vetores de recursos de 100 dimens√µes.<br>\n",
    "min_count = 2, ignora todas as palavras com frequ√™ncia total inferior a esta. <br>\n",
    "negativo = 5, especifica quantas ‚Äúpalavras de ru√≠do‚Äù devem ser desenhadas. <br>\n",
    "hs = 0, e negativo √© diferente de zero, amostragem negativa ser√° usada. <br>\n",
    "amostra = 0, o limite para configurar quais palavras de alta frequ√™ncia s√£o amostradas aleatoriamente. <br>\n",
    "trabalhadores = n√∫cleos, use esses muitos threads de trabalho para treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
