{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Trabalho de Análise de Sentimentos   </h2>\n",
    "<br>\n",
    "<b>Equipe: Igor, Jane, Jerusa e Leila   <br>\n",
    "  O artigo completo sobre Repeated k-Fold Cross-Validation pode ser encontrado neste site \n",
    "<a href='https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/'> neste dataset </a><br>\n",
    "    \n",
    "\n",
    "<h5>Versão 12/09/2020 - Criada a função Trata_Emojis() que traduz o sentimento da imagem.<br>\n",
    "    Versão 27/08/2020 - Corrigido arquivos com neutras e sem neutras.<br>\n",
    "    Versão 10/08/2020 - Organizado em funções e com o repeat k-fold. </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informando o número desejado de repetições para K-fold\n",
    "nrMaxTestes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\particular\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "import regex\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.svm          import LinearSVC\n",
    "from sklearn.cluster      import KMeans\n",
    "from sklearn.multiclass   import OneVsRestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets        import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import LinearSVC\n",
    "from matplotlib              import pyplot\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn import utils\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "def Carrega_Arquivo(plota_grafico):\n",
    "    #arquivo_f = 'Suicidas_NaoSuicidas_Testar-20200521.csv'\n",
    "    arquivo_f = 'Suicidas_NaoSuicidas_Testar-20200718.csv'\n",
    "    cabecalho_f = ['Polaridade', 'Frase']\n",
    "    with open(arquivo_f, 'rb') as f:\n",
    "        result_f = chardet.detect(f.read()) \n",
    "    data = pd.read_csv(arquivo_f, encoding=result_f['encoding'], sep=';', header=None, names=cabecalho_f)\n",
    "    \n",
    "    # Excluindo os registros com frase nulas\n",
    "    data = data[pd.notnull(data['Frase'])]\n",
    "\n",
    "    # criou a coluna Polaridade_id no dataframe df, que contém o nome polaridade representado por número\n",
    "    data['Polaridade_id'] = data['Polaridade'].factorize()[0]\n",
    "\n",
    "    if plota_grafico == 'SIM':\n",
    "        data['Polaridade'].value_counts().plot(kind='pie');\n",
    "        plt.title('ESSA É A DISTRIBUIÇÃO DOS DADOS DE ENTRADA')\n",
    "        plt.savefig(\"distribuicao_dados.png\")\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_Parametros():\n",
    "    efile = open(\"parametros.txt\", \"r\")\n",
    "    parametros = []\n",
    "    for nr, linha in enumerate(efile):\n",
    "        conteudo = linha.split(\";\") \n",
    "        parametros.append(conteudo) \n",
    "    efile.close()\n",
    "    return(parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Limpa_emojis(linha):\n",
    "    \n",
    "    data = regex.findall(r'\\X', linha)\n",
    "    for word in data:        \n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            # Remove emoji do texto\n",
    "            \n",
    "        \n",
    "    return (linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Of course, (too many) emoji [a lot] characters      feliz  like  , #@^!*&#@^#   helps   people read  achando engraçado demais aa achando engraçado demais aaa achando engraçado demais a #douchebag\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# https://emojipedia.org/people/\n",
    "# https://www.emoticonsignificado.com.br/lista-emojis-pessoas-whatsapp\n",
    "def Trata_Emojis(linha):\n",
    "    # Dicionário de emojis e emoções\n",
    "    emojis_lista = [('😊', ' feliz '), \n",
    "                    ('🤣', ' super feliz '), \n",
    "                    ('😂', ' achando engraçado demais ')\n",
    "                    ('😢', ' triste ')\n",
    "                    ('😭', ' muito triste ')\n",
    "                    ('😡', ' furioso ')\n",
    "                    ('😱', ' assustado ')\n",
    "                    ('😩', ' chateado ')\n",
    "                    ('😰', ' ansioso ')\n",
    "                    ('🤩', ' encantado')]\n",
    "    emojis_dict = dict(emojis_lista)\n",
    "    \n",
    "    # quebra a linha em caracteres \n",
    "    linha_quebrada = regex.findall(r'\\X', linha)\n",
    "     \n",
    "    for char in linha_quebrada:\n",
    "        if char in emoji.UNICODE_EMOJI:\n",
    "            char_demojize = emoji.demojize(char)\n",
    "            y = emoji.emojize(char_demojize)\n",
    "            emoji_sentimento =  emojis_dict.get(y, ' ')\n",
    "            linha = linha.replace(char, emoji_sentimento)  \n",
    "         \n",
    "    return(linha)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_Stopwords():\n",
    "    stopwords_nltk = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    f = open('stop_palavras.txt', 'r', encoding = 'utf-8')\n",
    "    tudo =  f.read()\n",
    "    palavras =  set(tudo.split())\n",
    "    nltk_mais_palavras = stopwords_nltk.union(palavras)\n",
    "    return(nltk_mais_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Limpa_Texto(instancia):\n",
    "    instancia = instancia.lower()  \n",
    "    acentos = str.maketrans(\"áéíóúâêôãõ\", \"aeiouaeoao\") \n",
    "    instancia = instancia.translate(acentos)\n",
    "    \n",
    "    instancia = Trata_Emojis(instancia)\n",
    "    instancia = re.sub(r'\\|\\|\\|', r'', instancia) \n",
    "    instancia = re.sub(r'http\\S+', r'', instancia)\n",
    "    instancia = instancia.replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','')    \n",
    "    instancia = instancia.replace('[','').replace(']','').replace('@','').replace('(','').replace('/','')   \n",
    "    instancia = instancia.replace('#','').replace('RT @','').replace('rt cvvoficial','')\n",
    "    instancia = instancia.replace('!','').replace('?','')\n",
    "   \n",
    "    stopwords = Carrega_Stopwords()\n",
    "    palavras = []\n",
    "    for i in instancia.split():\n",
    "        if not i.isnumeric(): \n",
    "            if not i in stopwords:\n",
    "                palavras.append(i)\n",
    "        \n",
    "               \n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Aplica_Stemizacao(instancia):\n",
    "    palavras = [stemmer.stem(i)  for i in instancia.split()]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    \n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transforma_Doc2vec(t_frases, t_polaridades):\n",
    "    \n",
    "    df_teste = pd.DataFrame({'Frase': t_frases, 'Polaridade_id':t_polaridades})\n",
    "    df_teste['tokenized'] = df_teste.apply(lambda row: nltk.word_tokenize(row['Frase']), axis=1)\n",
    "\n",
    "    train_tagged = df_teste.apply(\n",
    "            lambda r: TaggedDocument(r.tokenized, tags=[r.Polaridade_id]), axis=1)\n",
    "    \n",
    "    model_dmm = Doc2Vec(dm=1, vector_size=300, window=3, min_count=2, workers=cores)\n",
    "    model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])\n",
    "\n",
    "    for epoch in range(10):\n",
    "        model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "        model_dmm.alpha -= 0.002\n",
    "        model_dmm.min_alpha = model_dmm.alpha\n",
    "\n",
    "    y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "\n",
    "    # adapta as features a uma escala de [0 até 1]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_X_train = scaler.fit_transform(list(X_train))\n",
    "\n",
    "    return(scaled_X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Carrega_features_labels(tipo_NLP, q_frases, q_polaridades ):\n",
    "    \n",
    "    rotulos = q_polaridades\n",
    "      \n",
    "    if tipo_NLP == 'CountVectorizer':\n",
    "        v = CountVectorizer()\n",
    "        vetores = v.fit_transform(q_frases) \n",
    "        \n",
    "    if tipo_NLP == 'TF_IDF':\n",
    "        tfidf = TfidfVectorizer(use_idf=True, max_features=300, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "        vetores = tfidf.fit_transform(q_frases) \n",
    "        \n",
    "    if tipo_NLP == 'DOC2VEC':\n",
    "        vetores, rotulos  = Transforma_Doc2vec(q_frases, q_polaridades)\n",
    "    \n",
    " \n",
    "    return(vetores, rotulos)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calcula_Acuracia_Modelos(features, labels, MaxTeste, tipo_NLP, resultados, com_stemizacao, com_neutras):\n",
    "    \n",
    "    \n",
    "    models = [\n",
    "        RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "        LinearSVC(),\n",
    "        #OneVsRestClassifier(LinearSVC(), n_jobs=1),\n",
    "        MultinomialNB(),\n",
    "        LogisticRegression(random_state=0) ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "    print('Tipo Conversao NLP=> %s - stemizacao= %s e neutras=%s' %  (tipo_NLP, com_stemizacao, com_neutras))\n",
    "    print('--------------------------------------------------------------------------------------')\n",
    "         \n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        \n",
    "        results = []\n",
    "        numero = 0 \n",
    "        for repeats in range(1,MaxTeste):\n",
    "            CV = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "            # n_jobs = -1 significa usar todos os processadores\n",
    "            scores = cross_val_score(model, features, labels, scoring='accuracy', cv=CV, n_jobs=-1)\n",
    "            print('Modelo %s > Repetições=%d média=%.4f desvio padrão=%.3f' % (model_name, repeats, mean(scores), sem(scores)))\n",
    "           \n",
    "            # guarda o resultado\n",
    "            results.append(scores)\n",
    "            numero = repeats * 10 \n",
    "            #numero = int((numero + 1) * 10 )\n",
    "            resultados.append((tipo_NLP, com_stemizacao, testa_com_Neutra, numero, model_name, mean(scores)))\n",
    "            \n",
    "        # cria gráfico dos resultados\n",
    "        #pyplot.boxplot(results, labels=[str(r) for r in range(1,MaxTeste)], showmeans=True)\n",
    "        #pyplot.title(model_name)\n",
    "        #pyplot.show()\n",
    "        \n",
    "    return()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostrar_max_por_modelo(modelo, data_teste):\n",
    " \n",
    "    eh_modelo =  data_teste['tipo_NLP']==modelo\n",
    "    data_filtrada = data_teste[eh_modelo]\n",
    "    \n",
    "    max_value = data_filtrada['media_acuracia'].max()\n",
    "    eh_maior  = data_filtrada['media_acuracia']==max_value\n",
    "    data_filtrada = data_filtrada[eh_maior]\n",
    "    return(data_filtrada) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Resultados(Nome_Arquivo):\n",
    "\n",
    "    data_mostra = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "\n",
    "    # mostra execução que apresentou a maior acurácia\n",
    "    maximo = data_mostra['media_acuracia'].idxmax()\n",
    "    rowData = data_mostra.loc[maximo , : ]\n",
    "    linha_com_maximo = rowData.values.tolist()\n",
    "    df_teste = pd.DataFrame([linha_com_maximo])\n",
    "    df_teste.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "   \n",
    "    # mostra Máxima Acurácia por Modelo = \n",
    "    teste1 = Mostrar_max_por_modelo('CountVectorizer', data_mostra)\n",
    "    teste2 = Mostrar_max_por_modelo('TF_IDF', data_mostra)\n",
    "    teste3 = Mostrar_max_por_modelo('DOC2VEC', data_mostra)\n",
    "    teste_r = pd.concat([teste1, teste2, teste3])\n",
    "    teste_r.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    # mostra Valor Medio de Acuracia nas Iterações\n",
    "    Valor_Medio_Acuracia = data_mostra.groupby(['tipo_NLP', 'model_name']).agg({'media_acuracia': ['mean']})\n",
    "    Valor_Medio_Acuracia.columns = [ 'Acurácia Média']\n",
    "     \n",
    "    return(df_teste, teste_r, Valor_Medio_Acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Grafico(Nome_Arquivo):\n",
    "    # li dados\n",
    "    data_grafico = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "    data_grafico.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    # cria um DataFrame Pandas com resultado do filtro\n",
    "    result = data_grafico.groupby(['tipo_NLP','model_name'])[['media_acuracia']].mean()\n",
    "\n",
    "    # gera uma lista com os valores de acurácia \n",
    "    valores = list(result.media_acuracia) \n",
    "\n",
    "    labels = list(np.unique(data_grafico.model_name))\n",
    "\n",
    "    # os 4 primeiros na lista de valores são do countvectorizer\n",
    "    medias_countvectorizer = valores[0:4]\n",
    "    medias_tfidf = valores[4:8]\n",
    "    medias_doc2vec = valores[8:12]\n",
    "\n",
    "    # Definindo a largura das barras\n",
    "    barWidth = 0.25\n",
    "\n",
    "    # Aumentando o gráfico\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Definindo a posição das barras\n",
    "    r1 = np.arange(len(medias_countvectorizer))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    # Criando as barras\n",
    "    plt.bar(r1, medias_countvectorizer, color='#6A5ACD', width=barWidth, label='CountVectorizer')\n",
    "    plt.bar(r2, medias_tfidf, color='#00BFFF', width=barWidth, label='TF-IDF')\n",
    "    plt.bar(r3, medias_doc2vec, color='#48F317', width=barWidth, label='DOC2VEC')\n",
    "\n",
    "    # Adiciando legendas as barras\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.xticks([r + barWidth for r in range(len(medias_countvectorizer))], labels)\n",
    "    plt.ylabel('Acurácia Média')\n",
    "    plt.title('Representação Acurácia Média por Modelo')\n",
    "        \n",
    "\n",
    "    # Criando a legenda e exibindo o gráfico\n",
    "    plt.legend()\n",
    "    plt.savefig(\"acuracia_por_modelo.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mostra_Grafico_por_Opcao(Nome_Arquivo, opcao):\n",
    "    \n",
    "    arquivo_res = pd.read_csv(Nome_Arquivo, sep=\",\")\n",
    "    arquivo_res.columns = ['nr','tipo_NLP', 'com_stemizacao', 'testa_com_Neutra', 'repeticoes', 'model_name', 'media_acuracia']\n",
    "    \n",
    "    if opcao == 'SEM_NEUTRAS':\n",
    "        data_grafico = arquivo_res[arquivo_res['testa_com_Neutra'] == 'NAO']\n",
    "        titulo = 'Sem Incluir Frases Neutras'\n",
    "        nome_grafico = 'sem_neutras.png'\n",
    "    elif opcao == \"COM_STEMMIZACAO\":\n",
    "        data_grafico = arquivo_res[arquivo_res['com_stemizacao'] == 'SIM']\n",
    "        titulo = 'Utilizando a Stemmização'\n",
    "        nome_grafico = 'com_stemizacao.png'\n",
    "        \n",
    "    # cria um DataFrame Pandas com resultado do filtro\n",
    "    result = data_grafico.groupby(['tipo_NLP','model_name'])[['media_acuracia']].mean()\n",
    "\n",
    "    # gera uma lista com os valores de acurácia \n",
    "    valores = list(result.media_acuracia) \n",
    "\n",
    "    labels = list(np.unique(data_grafico.model_name))\n",
    "   \n",
    "    # os 4 primeiros na lista de valores são do countvectorizer\n",
    "    medias_countvectorizer = valores[0:4]\n",
    "    medias_tfidf = valores[4:8]\n",
    "    medias_doc2vec = valores[8:12]\n",
    "\n",
    "    # Definindo a largura das barras\n",
    "    barWidth = 0.25\n",
    "\n",
    "    # Aumentando o gráfico\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Definindo a posição das barras\n",
    "    r1 = np.arange(len(medias_countvectorizer))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    r3 = [x + barWidth for x in r2]\n",
    "\n",
    "    # Criando as barras\n",
    "    plt.bar(r1, medias_countvectorizer, color='#6A5ACD', width=barWidth, label='CountVectorizer')\n",
    "    plt.bar(r2, medias_tfidf, color='#00BFFF', width=barWidth, label='TF-IDF')\n",
    "    plt.bar(r3, medias_doc2vec, color='#48F317', width=barWidth, label='DOC2VEC')\n",
    "\n",
    "    # Adiciando legendas as barras\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.xticks([r + barWidth for r in range(len(medias_countvectorizer))], labels)\n",
    "    plt.ylabel('Acurácia Média')\n",
    "    plt.title(titulo)\n",
    "\n",
    "    # Criando a legenda e exibindo o gráfico\n",
    "    plt.legend()\n",
    "    plt.savefig(nome_grafico)\n",
    "    plt.show()\n",
    "\n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grava_Resultados(resultados):\n",
    "    NomArq = 'resultados_'  + str(datetime.now().strftime('%Y_%m_%d_%H_%M_%S')) + '.csv'\n",
    "    resultados_df = pd.DataFrame(resultados, columns=['tipo_NLP', 'com_stemizacao', 'testa_com_Neutra','repeticoes', 'model_name', 'media_acuracia'])\n",
    "    resultados_df.to_csv(NomArq)\n",
    "    return(NomArq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INICIO DO PROCESSAMENTO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = Carrega_Arquivo('SIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplica a função de limpeza de caracteres em todos os dados:\n",
    "data.Frase = [Limpa_Texto(i) for i in data.Frase]\n",
    "\n",
    "# cria coluna com frases stemizadas \n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "data['Frase_Stemm'] = [Aplica_Stemizacao(j) for j in data.Frase]\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro  = data['Polaridade'] != 'Neutra'\n",
    "data_sem_neutras = data[filtro]\n",
    "#data_sem_neutras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frases limpas são salvas para uso em outros programas.\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "# Salvando dataframe para usar em Pipe_Doc2Vec\n",
    "pickle.dump(data, open(\"dados_treino.pickle\", 'wb'))\n",
    "\n",
    "# Salvando frases para usar no K-Means\n",
    "frases_file = 'Frases_Limpas.pickle'\n",
    "pickle.dump(data.Frase, open(frases_file, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explicação sobre K-repeated e K-fold está na última célula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca definições para parâmetros\n",
    "parametros = Carrega_Parametros()\n",
    "\n",
    "# inicializa lista de resultados\n",
    "resultados = []\n",
    "\n",
    "for lin in range(1,len(parametros)):\n",
    "\n",
    "    tipo_NLP         = parametros[lin][0]\n",
    "    com_stemizacao   = parametros[lin][1]\n",
    "    testa_com_Neutra = parametros[lin][2]\n",
    "    com_stemizacao   = com_stemizacao.strip()\n",
    "    testa_com_Neutra = testa_com_Neutra.strip()\n",
    "\n",
    "    x_frases = []\n",
    "    if testa_com_Neutra == 'SIM':\n",
    "        x_polaridades = data.Polaridade_id \n",
    "        \n",
    "        if com_stemizacao == 'SIM':\n",
    "            x_frases = data.Frase_Stemm\n",
    "            \n",
    "        if com_stemizacao == 'NAO':\n",
    "            x_frases = data.Frase\n",
    "            \n",
    "\n",
    "    if testa_com_Neutra == 'NAO':\n",
    "        x_polaridades = data_sem_neutras.Polaridade_id \n",
    "        \n",
    "        if com_stemizacao == 'SIM':\n",
    "            x_frases = data_sem_neutras.Frase_Stemm\n",
    "           \n",
    "        if com_stemizacao == 'NAO':\n",
    "            x_frases = data_sem_neutras.Frase \n",
    "    \n",
    "\n",
    "    \n",
    "    features, labels = Carrega_features_labels(tipo_NLP, x_frases, x_polaridades)\n",
    "      \n",
    "    Calcula_Acuracia_Modelos(features, labels, nrMaxTestes, tipo_NLP, resultados, com_stemizacao, testa_com_Neutra)\n",
    "\n",
    "# salva os resultados\n",
    "print('*** Salvando Resultados ***')\n",
    "Nome_Arquivo = Grava_Resultados(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra os resultados\n",
    "df1, df2, df3 = Mostra_Resultados(Nome_Arquivo)\n",
    "printmd('**Maior Acurácia nos Testes**')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Máxima Acurácia por Modelo**')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd('**Valor Medio de Acuracia nas Iterações**')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apresenta gráfico contendo as médias de acurácia encontradas\n",
    "Mostra_Grafico(Nome_Arquivo)\n",
    "Mostra_Grafico_por_Opcao(Nome_Arquivo, \"SEM_NEUTRAS\")\n",
    "Mostra_Grafico_por_Opcao(Nome_Arquivo, \"COM_STEMMIZACAO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ==> Escolhemos manualmente o modelo que apresentou melhor performance <br>\n",
    "    <br>\n",
    "\n",
    " \n",
    " ## Observando resultados acima vimos que:\n",
    " <h3><i> Os resultados mostram que o LinearSVC apresentou melhor performance,tanto com TF-IDF quanto DOC2VEC:<br>\n",
    "    -     LinearSVC                     0.780115  (TFIDF)<br>   \n",
    "    -     LinearSVC                     0.769629 (DOC2VEC) <br>\n",
    " o Multinomial foi o melhor para CountVectorizer. <br>\n",
    " Além disso, observamos que a melhor acurácia aconteceu quando  NAO usamos Neutras e NAO usamos stemização.\n",
    " \n",
    "\n",
    "- A maior acurácia foi igual a 0.8498508098891732, utilizando o modelo Multinomial, usando 'CountVectorizer'.<br>\n",
    "\n",
    "- Embora o CountVectorizer tenha apresentado melhor acurácia, o método é considerado menos <br>\n",
    "  eficiente que o TF-IDF, por essa razão estamos elegendo o que apresentou melhor desempenho no TF-IDF.\n",
    "  \n",
    "- A seguir treinaremos o LinearSVC, com TF-IDF, sem stemização e sem frases Neutras. </i></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><i><b>Validação cruzada do k-Fold</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pegando o arquivo sem usar frases neutras e a coluna 'Frase'  que não tem stemmização\n",
    "# não incluir neutras => usar  data_sem_neutras\n",
    "# incluir stemmização => usar data.Frase_Stemm\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a linearSVC model using k-fold cross-validation\n",
    "# https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets        import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.svm             import LinearSVC\n",
    "from matplotlib              import pyplot\n",
    "\n",
    "#tfidf = TfidfVectorizer(use_idf=True, max_features=300, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "tfidf = TfidfVectorizer(use_idf=True, max_df=5, min_df=1, norm='l2', encoding='utf-8', ngram_range=(1,2))\n",
    "\n",
    "# prepara labels e features\n",
    "#features = tfidf.fit_transform(data_sem_neutras.Frase)\n",
    "#features = tfidf.fit_transform(data_sem_neutras.Frase_Stemm)\n",
    "#labels = data_sem_neutras.Polaridade_id\n",
    "features = tfidf.fit_transform(data.Frase)\n",
    "#features = tfidf.fit_transform(data.Frase_Stemm)\n",
    "labels = data.Polaridade_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria matriz para mostrar palavras utilizadas \n",
    "matriz_tfidf = pd.DataFrame(features.toarray(), columns=tfidf.get_feature_names())\n",
    "matriz_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avalia o modelo com um dado nr de repetições\n",
    "def evaluate_model(X, y, repeats):\n",
    "    # prepara a cross-validation  \n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "    # cria o modelo\n",
    "    model = LinearSVC()\n",
    "    # avalia o modelo\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return(scores)  \n",
    "\n",
    "# configurações de teste\n",
    "results = list()\n",
    "\n",
    "for r in range(1,16):\n",
    "    scores = evaluate_model(features, labels, r)\n",
    "    print('LinearSVC > Repetições=%d média=%.4f desvio padrão=%.3f ' % (r, mean(scores), sem(scores)))\n",
    "    \n",
    "    # guarda o resultado\n",
    "    results.append(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria gráfico dos resultados\n",
    "pyplot.boxplot(results, labels=[str(r) for r in range(1,16)], showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    " ## Analisando resultados:\n",
    "<i>\n",
    "- A linha laranja indica a mediana da distribuição e o triângulo verde representa a média aritmética. Na sexta repetição vemos que  os valores coincidem, e isso sugere uma distribuição simétrica bem razoável, e que a média conseguiu capturar bem a tendência central. Isso nos ajuda a escolher o número apropriado de repetições para o processo de teste. <br>\n",
    "Usaremos 6 repetições.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinando o LinearSVC utilizando TF-IDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm             import LinearSVC \n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "# Separando dados de treino e teste \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.10, random_state=0)\n",
    "\n",
    "\n",
    "# Treina o modelo\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "\n",
    "Score = model.score(X_test,y_test) \n",
    "print('Score=', Score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando o Modelo Vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# O Modelo é salvo para classificar twitters no programa Analise_Twitters_CVV.ipynb.\n",
    "import pickle\n",
    "import os \n",
    "\n",
    "#os.chdir('C:\\\\Users\\\\particular\\\\SERIQUE_TCC\\\\FINAL DA POS\\\\')\n",
    "\n",
    "# Salvando modelo\n",
    "model_file = 'model_LinearSVC.pickle'\n",
    "pickle.dump(model, open(model_file, 'wb'))\n",
    "\n",
    "# Salvando tfidf\n",
    "tfidf_file = 'tfidf_file.pickle'\n",
    "pickle.dump(tfidf, open(tfidf_file, 'wb'))\n",
    "\n",
    "print(\"Dados salvos!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário para polaridade  \n",
    "id_to_Polaridade = {0: 'Negativa', 1: 'Positiva', 2: 'Neutra'}\n",
    "\n",
    "texts = [\"Estou em beco sem saida, o unico jeito é tomar todos comprimidos e dormir para sempre.\",\n",
    "         \"Estranho que não sinto forças para levantar da cama. Preciso de ajuda.\",\n",
    "         \"Adoro viver, cantar e sorrir todo dia.\", \n",
    "          \"Minha vida é um pesadelo imenso, estou muito triste.\", \n",
    "          \"O jogo foi adiado para amanhã.\"]\n",
    "corretas = [1, 1, 0, 1, 2]\n",
    "\n",
    "text_features = tfidf.transform(texts)\n",
    "\n",
    "nr = 0 \n",
    "acertou = 0 \n",
    "predictions = model.predict(text_features)\n",
    "for text, predicted in zip(texts, predictions):\n",
    "    print('\"{}\"'.format(text))\n",
    "    print(\"  - Classificada como: '{}'\".format(id_to_Polaridade[predicted]))\n",
    "    print(\"  - O correto é      : '{}'\".format(id_to_Polaridade[corretas[nr]]))\n",
    "    print(\"\")\n",
    "    if predicted == corretas[nr]:\n",
    "        acertou += 1\n",
    "    nr += 1\n",
    "print('-' * 50)\n",
    "print('acertou = ', acertou,  '/', len(texts)) \n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSÃO: A assertividade em frases que não estavam no modelo foi péssima, apesar do modelo ter sido considerado o melhor nos testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('*** A C A B E I ***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b> Descobrindo o melhor k-fold.</b>\n",
    "O procedimento de validação cruzada com dobra k divide um conjunto de dados limitado em k dobras sem sobreposição. Cada uma das k dobras tem a oportunidade de ser usada como um conjunto de testes retidos, enquanto todas as outras dobras coletivamente são usadas como um conjunto de dados de treinamento. Um total de k modelos são ajustados e avaliados nos conjuntos de testes de espera k e o desempenho médio é relatado.\n",
    "   \n",
    "¨ A validação cruzada repetida em dobra k replica o procedimento […] várias vezes. Por exemplo, se a validação cruzada 10 vezes foi repetida cinco vezes, 50 conjuntos diferentes retidos seriam usados para estimar a eficácia do modelo.¨\n",
    "\n",
    "- Página 70, Modelagem Preditiva Aplicada , 2013.\n",
    "Applied Predictive Modeling 1st ed. 2013, Corr. 2nd printing 2018 Edition\n",
    "by Max Kuhn  (Author), Kjell Johnson  (Author)\n",
    "    \n",
    "  \n",
    "O desempenho médio relatado de uma única execução de validação cruzada k-fold pode ser barulhento.\n",
    "A validação cruzada repetida de dobras k fornece uma maneira de reduzir o erro na estimativa do desempenho médio do modelo.\n",
    "Como avaliar modelos de aprendizado de máquina usando a validação cruzada k-fold repetida no Python.\n",
    "\n",
    "Nesse caso, podemos ver que o padrão de uma repetição parece otimista em comparação com os outros resultados, com uma precisão de cerca de 86,80 por cento em comparação com 86,73 por cento e menor com números diferentes de repetições.\n",
    "\n",
    "Podemos ver que a média parece coalescer em torno de um valor de cerca de 86,5%. Podemos considerar isso como uma estimativa estável do desempenho do modelo e, por sua vez, escolher 5 ou 6 repetições que parecem aproximar esse valor primeiro.\n",
    "\n",
    "Observando o erro padrão, podemos ver que ele diminui com um aumento no número de repetições e se estabiliza com um valor em torno de 0,003, em torno de 9 ou 10 repetições, embora 5 repetições atinjam um erro padrão de 0,005, metade da alcançada com um repetição única."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos variar os seguintes parâmetros:<br>\n",
    "Se dm = 0, é usado opacote distribuído de palavras (PV-DBOW) ; <br>\n",
    "se dm = 1, 'memória distribuída' (PV-DM) é usada. <br>\n",
    "Vetores de recursos de 100 dimensões.<br>\n",
    "min_count = 2, ignora todas as palavras com frequência total inferior a esta. <br>\n",
    "negativo = 5, especifica quantas “palavras de ruído” devem ser desenhadas. <br>\n",
    "hs = 0, e negativo é diferente de zero, amostragem negativa será usada. <br>\n",
    "amostra = 0, o limite para configurar quais palavras de alta frequência são amostradas aleatoriamente. <br>\n",
    "trabalhadores = núcleos, use esses muitos threads de trabalho para treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
